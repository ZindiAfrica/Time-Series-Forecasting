{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "pk5WiopT9oJw",
    "outputId": "446b6db5-1cbe-4beb-e1e2-4bcdd512bab6"
   },
   "outputs": [],
   "source": [
    "# installing catboost\n",
    "# Catboost == 0.22 was the version of catboost at the start of this competition\n",
    "!pip install catboost==0.22 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "jVXG4QlTuVYr"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from functools import reduce\n",
    "from time import time\n",
    "\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)           \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "VJjtuM3kvCAT"
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "train = pd.read_csv('./input/Train.csv')\n",
    "test = pd.read_csv('./input/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "4MhDKOpYF9dm"
   },
   "outputs": [],
   "source": [
    "# Separating the target variable from the training dataframe\n",
    "#\n",
    "target = train.target\n",
    "\n",
    "# Aligning the train and test dataframes\n",
    "#\n",
    "train, test = train.align(test, join='inner', axis=1)\n",
    "\n",
    "# Creating a separator column to both train and test,\n",
    "# This is to be used in separation\n",
    "#\n",
    "train['separator'] = 0\n",
    "test['separator'] = 1\n",
    "\n",
    "# Combing the train and test dataframes together\n",
    "#\n",
    "comb = pd.concat([train, test])\n",
    "\n",
    "# Creating a function to replace all spaces in the dataframe with np.nan\n",
    "#\n",
    "def replace_nan(x):\n",
    "    if x == \" \":\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(x)\n",
    "\n",
    "# Creating a list of the main columns\n",
    "#\n",
    "main_cols = [\"temp\", \"precip\", \"rel_humidity\", \"wind_dir\", \"wind_spd\", \"atmos_press\"]\n",
    "\n",
    "# Replacing spaces with np.nan\n",
    "#\n",
    "for col in main_cols: \n",
    "    comb[col] = comb[col].apply(lambda x: [replace_nan(X) for X in x.replace(\"nan\", \" \").split(\",\")])\n",
    "\n",
    "def make_columns(feature):\n",
    "    return [f\"{feature}_{i}\" for i in range(1, 122)]\n",
    "    \n",
    "# Generating dataframes of hours for each main column\n",
    "#\n",
    "comb_temp         = pd.DataFrame([x for x in comb.temp],         columns=make_columns('temp'))\n",
    "comb_precip       = pd.DataFrame([x for x in comb.precip],       columns=make_columns('precip'))\n",
    "comb_rel_humidity = pd.DataFrame([x for x in comb.rel_humidity], columns=make_columns('rel_humidity'))\n",
    "comb_wind_dir     = pd.DataFrame([x for x in comb.wind_dir],     columns=make_columns('wind_dir'))\n",
    "comb_wind_spd     = pd.DataFrame([x for x in comb.wind_spd],     columns=make_columns('wind_spd'))\n",
    "comb_atmos_press  = pd.DataFrame([x for x in comb.atmos_press],  columns=make_columns('atmos_press'))\n",
    "\n",
    "comb_temp['ID'], comb_precip['ID'], comb_rel_humidity['ID'], comb_wind_dir['ID'], comb_wind_spd['ID'], comb_atmos_press['ID'] = [list(comb.ID)] * 6\n",
    "\n",
    "# Combining the generated dataframes together\n",
    "#\n",
    "comb_dfs = [comb, comb_temp, comb_precip, comb_rel_humidity, comb_wind_dir, comb_wind_spd, comb_atmos_press]\n",
    "comb = reduce(lambda  left, right: pd.merge(left, right, on=['ID'], how='outer'), comb_dfs)\n",
    "comb.drop(main_cols, axis=1, inplace=True)\n",
    "df = comb.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "id": "3FLjxrAXYbRV",
    "outputId": "5d01c7d2-cf39-49ce-d234-6c735a3971d7"
   },
   "outputs": [],
   "source": [
    "# Creating original series for each feature\n",
    "orig_cols_dict = {}\n",
    "weather_cols = ['temp', 'precip', 'rel_humidity', 'wind_dir','wind_spd', 'atmos_press']\n",
    "\n",
    "for w in tqdm_notebook(weather_cols):\n",
    "    selected_cols = [c for c in df.columns if w in c]\n",
    "    orig_cols_dict[w] = pd.Series(selected_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "oAGDsJ92YS2Z",
    "outputId": "3c4077e0-d77c-4feb-e744-4ef904531c04"
   },
   "outputs": [],
   "source": [
    "# Aggregating features per hour\n",
    "\n",
    "for w in tqdm_notebook(weather_cols):\n",
    "    tmp_df = pd.DataFrame()\n",
    "    tmp_df['weather_col_orig'] = orig_cols_dict[w]\n",
    "    tmp_df['hours_since_start'] = tmp_df['weather_col_orig'].apply(lambda x: x.split('_')[-1]).astype('int')\n",
    "    tmp_df['hour_of_day'] = tmp_df['hours_since_start'] % 24\n",
    "\n",
    "    for hour in range(1, 25):\n",
    "        selected_cols = tmp_df[tmp_df['hour_of_day'] == hour]['weather_col_orig'].tolist()\n",
    "        df_cols = df[selected_cols] # factorizing this part\n",
    "        \n",
    "        df[f'{w}_hour_{hour}_mean'] = df_cols.mean(axis=1)\n",
    "        df[f'{w}_hour_{hour}_min'] = df_cols.min(axis=1)\n",
    "        df[f'{w}_hour_{hour}_max'] = df_cols.max(axis=1)\n",
    "        df[f'{w}_hour_{hour}_range'] = df[f'{w}_hour_{hour}_max'] - df[f'{w}_hour_{hour}_min']\n",
    "        df[f'{w}_hour_{hour}_skew'] = df_cols.skew()\n",
    "        df[f'{w}_hour_{hour}_kurt'] = df_cols.kurt()\n",
    "\n",
    "        if hour - 3 > 0 and hour % 3 == 0:\n",
    "            df[f'{w}_hour_{hour}_prev_hour_mean_diff'] = df[f'{w}_hour_{hour}_mean'] - df[f'{w}_hour_{hour - 3}_mean']\n",
    "        if hour - 5 > 0 and hour % 3 == 0:\n",
    "            df[f'{w}_hour_{hour}_prev_hour_mean_diff_5'] = df[f'{w}_hour_{hour}_mean'] - df[f'{w}_hour_{hour - 5}_mean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "pEyFVf1lqInY"
   },
   "outputs": [],
   "source": [
    "comb = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "WCp_Ukh-NTso",
    "outputId": "104e385d-04c6-47af-8bec-582bc0fdfbac"
   },
   "outputs": [],
   "source": [
    "comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "xzn_w6FYftB8",
    "outputId": "33af157e-0c05-4be9-fd8f-3290f64fcd47"
   },
   "outputs": [],
   "source": [
    "# Creating aggregation features for each variable\n",
    "aggs = ['mean', 'std', 'var', 'kurt', 'skew', 'max', 'median', 'sum', 'mode', 'sem', 'min']\n",
    "\n",
    "for col in tqdm_notebook(main_cols):\n",
    "    for ag in tqdm(aggs):\n",
    "        selected_cols = [x for x in comb.columns if x.startswith(col)]\n",
    "\n",
    "        if ag == 'mode':\n",
    "            aggregate = comb[selected_cols].agg(ag, axis=1)[0]\n",
    "        else:\n",
    "            aggregate = comb[selected_cols].agg(ag, axis=1)\n",
    "        \n",
    "        comb[col[0] + col[-1] + '_' + ag] = aggregate\n",
    "\n",
    "# Creating separate dataframes for each variable\n",
    "# Creating a list of columns for each separate dataframe\n",
    "temp_cols = [x for x in comb.columns if x.startswith('temp')]\n",
    "temp = comb[temp_cols]\n",
    "\n",
    "precip_cols = [x for x in comb.columns if x.startswith('precip')]\n",
    "precip = comb[precip_cols]\n",
    "\n",
    "humid_cols = [x for x in comb.columns if x.startswith('rel_humidity')]\n",
    "humid = comb[humid_cols]\n",
    "\n",
    "wind_dir_cols = [x for x in comb.columns if x.startswith('wind_dir')]\n",
    "wind_dir = comb[wind_dir_cols]\n",
    "\n",
    "wind_spd_cols = [x for x in comb.columns if x.startswith('wind_spd')]\n",
    "wind_spd  = comb[wind_spd_cols]\n",
    "\n",
    "atmp_cols = [x for x in comb.columns if x.startswith('atmos_press')]\n",
    "atmp = comb[atmp_cols]\n",
    "\n",
    "fill_cols = comb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "qdVrf3ZmcFZn"
   },
   "outputs": [],
   "source": [
    "# Generating new features, by adding each variable per hour\n",
    "for x, y, z, a, b in zip(temp.columns, precip.columns, humid.columns, wind_spd.columns, atmp.columns):\n",
    "    comb['add_tp' + y[-4:]] = temp[x] + precip[y] + humid[z] + wind_spd[a] + atmp[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "IU2Z7uDigrgW"
   },
   "outputs": [],
   "source": [
    "# Filling missing values using forward fill\n",
    "comb = comb.ffill(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "aQTxY80kZ6rH",
    "outputId": "a2e1dfe2-2032-4666-9921-e523a4e566e6"
   },
   "outputs": [],
   "source": [
    "comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_qcut(feat):\n",
    "    return pd.qcut(comb[feat], 24, labels=False, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_features = [x for x in comb.columns if x not in ['separator', 'ID', 'location']]\n",
    "\n",
    "# Multiprocessing trick: 15 seconds instead of 7 minutes !\n",
    "binned_data = joblib.Parallel(n_jobs=-1, backend='multiprocessing')(\n",
    "    joblib.delayed(apply_qcut)(feat) for feat in tqdm_notebook(other_features))\n",
    "\n",
    "comb_binned_data = pd.concat(binned_data, axis=1)\n",
    "comb = pd.concat([comb[['separator', 'ID', 'location']], comb_binned_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "w-60osCYdgjT",
    "outputId": "7dc3c3bd-ef95-4d34-f090-3c7efb05081a"
   },
   "outputs": [],
   "source": [
    "# Separating train and test from the combined dataframe\n",
    "train = comb[comb.separator == 0]\n",
    "test = comb[comb.separator == 1]\n",
    "train.drop('separator', axis=1, inplace=True)\n",
    "test.drop('separator', axis=1, inplace=True)\n",
    "\n",
    "# Creating a list of test ids in the order that they will be trained\n",
    "testA =  test[test.location == 'A']\n",
    "testB =  test[test.location == 'B']\n",
    "testC =  test[test.location == 'C']\n",
    "testD =  test[test.location == 'D']\n",
    "testE =  test[test.location == 'E']\n",
    "\n",
    "tA, tD, tE, tBC = testA.ID, testD.ID, testE.ID, test[(test.location == 'B') | (test.location == 'C')].ID\n",
    "test_id = pd.concat([tA, tD, tE, tBC])\n",
    "\n",
    "# Adding back target to the train set\n",
    "train['target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end = time()\n",
    "print(f\"Total preprocessing time = {end - start:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "130zceoDarsp"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Creating X and y values\n",
    "X = train.drop(['ID', 'location', 'target'], axis=1)\n",
    "y = target.values\n",
    "\n",
    "# Shuffling the X, y values\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "tes = test.drop(['ID', 'location'], axis=1)\n",
    "\n",
    "# Traing the model across multiple seeds\n",
    "predictions = []\n",
    "for i in tqdm_notebook(range(25)):\n",
    "    cat = CatBoostRegressor(verbose=False, random_seed=i)\n",
    "    cat.fit(X, y)\n",
    "    \n",
    "    preds = cat.predict(tes)\n",
    "    predictions.append(preds)\n",
    "\n",
    "# Averaging the predictions\n",
    "avg_preds = np.mean(predictions, axis=0)\n",
    "\n",
    "# Post processing of the predictions\n",
    "# This post processing was done with the help of a validation set.\n",
    "# The validation set was adversarial, i.e. we chose the examples from the training set closest to the test set, and applied post processing to it.\n",
    "post_proc = [((((((((((x-0.85)*1.015)-0.85)*1.012)-0.75)*1.0095)-0.55)*1.0065)-0.8)*1.007) for x in avg_preds]\n",
    "post_proc = predzz = [((x-0.85)*1.015) for x in post_proc]\n",
    "\n",
    "# Creating a submission file\n",
    "sub_df = pd.DataFrame({'ID': test.ID, 'target': post_proc})\n",
    "sub_df.to_csv('model_1_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "nrK5eVysjIna",
    "outputId": "8846d85a-7616-49b3-b0db-d87fc502c993"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Creating a list to hold predictions per seed\n",
    "predzz = []\n",
    "for i in tqdm_notebook(range(25), leave=False):\n",
    "    # Creating a list to hold predictions per location\n",
    "    # Training model per location per seed\n",
    "    predictions = []\n",
    "    for area in tqdm_notebook(['A', 'D', 'E'], leave=False):\n",
    "        # Separating training data per location\n",
    "        X = train[train.location == area]\n",
    "        y = X.target\n",
    "        X = X.drop(['ID', 'location', 'target'], axis=1)\n",
    "\n",
    "        # Shuffling data\n",
    "        X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "        # Separating testing data per location\n",
    "        tes = test[test.location == area]\n",
    "        tes = tes.drop(['ID', 'location'], axis=1)\n",
    "\n",
    "        # Training the model and making predictions per seed, per location\n",
    "        preds = CatBoostRegressor(verbose=False, random_seed=i).fit(X, y).predict(tes)\n",
    "        predictions.extend(preds)\n",
    "\n",
    "    X = train[(train.location == 'B') | (train.location == 'C')]\n",
    "    y = X.target\n",
    "    X = X.drop(['ID', 'location', 'target'], axis=1)\n",
    "    X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "    tes = test[(test.location == 'B') | (test.location == 'C')]\n",
    "    tes = tes.drop(['ID', 'location'], axis=1)\n",
    "    preds = CatBoostRegressor(verbose=False, random_seed=i).fit(X, y).predict(tes)\n",
    "    predictions.extend(preds)\n",
    "\n",
    "    predzz.append(predictions)\n",
    "\n",
    "# Averaging the predictions\n",
    "preds_av = np.mean(predzz, axis=0)\n",
    "\n",
    "# Post processing of the predictions\n",
    "# This post processing was done with the help of a validation set.\n",
    "# The validation set was adversarial, i.e. we chose the examples from the training set closest to the test set, and applied post processing to it.\n",
    "predz = [((((((((((x-0.85)*1.015)-0.85)*1.012)-0.75)*1.0095)-0.55)*1.0065)-0.8)*1.007) for x in preds_av]\n",
    "predzz = [((x-0.85)*1.015) for x in predz]\n",
    "\n",
    "# Creating a submission file\n",
    "sub_df = pd.DataFrame({'ID': test_id, 'target': predzz})\n",
    "sub_df.to_csv('model_1_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.979202</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B\n",
       "A  1.000000  0.979202\n",
       "B  0.979202  1.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_df = pd.read_csv('model_1_1.csv')[['ID']]\n",
    "blend_df['A'] = pd.read_csv('model_1_1.csv')['target']\n",
    "blend_df = pd.merge(blend_df, pd.read_csv('model_1_2.csv').rename({'target': 'B'}, axis=1), on = 'ID', how = 'left')\n",
    "blend_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blend_df['target'] = blend_df['A']*0.5 + blend_df['B']*0.5\n",
    "blend_df[['ID', 'target']].to_csv('model_12_blend.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979202</td>\n",
       "      <td>0.994761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.979202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.994761</td>\n",
       "      <td>0.994813</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A         B    target\n",
       "A       1.000000  0.979202  0.994761\n",
       "B       0.979202  1.000000  0.994813\n",
       "target  0.994761  0.994813  1.000000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUB_FILE_NAME = 'model_12_blend.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_test_0</td>\n",
       "      <td>158.123774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_test_1</td>\n",
       "      <td>97.217908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_test_10</td>\n",
       "      <td>21.393733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_test_100</td>\n",
       "      <td>63.222891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_test_1000</td>\n",
       "      <td>92.046200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID_test_1001</td>\n",
       "      <td>44.955298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID_test_1002</td>\n",
       "      <td>83.270765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ID_test_1003</td>\n",
       "      <td>36.458014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ID_test_1004</td>\n",
       "      <td>34.101068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ID_test_1005</td>\n",
       "      <td>47.728921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID      target\n",
       "0     ID_test_0  158.123774\n",
       "1     ID_test_1   97.217908\n",
       "2    ID_test_10   21.393733\n",
       "3   ID_test_100   63.222891\n",
       "4  ID_test_1000   92.046200\n",
       "5  ID_test_1001   44.955298\n",
       "6  ID_test_1002   83.270765\n",
       "7  ID_test_1003   36.458014\n",
       "8  ID_test_1004   34.101068\n",
       "9  ID_test_1005   47.728921"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_df[['ID', 'target']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=model_12_blend.csv>Download CSV file</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "def create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "create_download_link(filename = SUB_FILE_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
